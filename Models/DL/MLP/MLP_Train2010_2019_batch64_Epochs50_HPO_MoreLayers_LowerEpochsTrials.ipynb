{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MaritimeTradeCOVID_MLP_Train2010_2019_batch64_Epochs50_HPO_MoreLayers_LowerEpochsTrials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adataschultz/MaritimeTrade_COVID/blob/main/MLP_Regression/MaritimeTradeCOVID_MLP_Train2010_2019_batch64_Epochs50_HPO_MoreLayers_LowerEpochsTrials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpTmKtBVKMKT"
      },
      "source": [
        "######################################################\n",
        "#### 2010 - 2019 Maritime Trade with COVID - MLP #####\n",
        "##########  Hyperparameter Optimization ##############\n",
        "######################################################"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPD1AoKmuksU",
        "outputId": "eaffb387-f558-4c31-8c52-83e66cd3330c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOReN1GxuoCI",
        "outputId": "ba006e35-96d6-413e-fe9a-6b691200d5c3"
      },
      "source": [
        "%cd /content/drive/MyDrive/Data_MaritimeTrade_MLP/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data_MaritimeTrade_MLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJsjiI7GlIeX",
        "outputId": "303d78a0-3327-45ce-861c-ccb7344cf607"
      },
      "source": [
        "# Install and import packages\n",
        "!pip install category_encoders\n",
        "!pip install keras-tuner\n",
        "from tensorflow import keras\n",
        "import keras_tuner\n",
        "from keras_tuner import BayesianOptimization\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import category_encoders as ce\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print('\\n')\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
        "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.6.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.41.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.4.3)\n",
            "\n",
            "\n",
            "TensorFlow version: 2.6.0\n",
            "Eager execution is: True\n",
            "Keras version: 2.6.0\n",
            "Num GPUs Available:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq4OU14dx8-q"
      },
      "source": [
        "# Reproducibility in TF and Pytorch \n",
        "def init_seeds(seed=1019):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    session_conf = tf.compat.v1.ConfigProto()\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] ='true'\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = 'true'\n",
        "    tf.random.set_seed(seed)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(),config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "    return sess"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjzKoSqW-5kS",
        "outputId": "1eb8b6fb-f99d-4904-b1d0-fd3618f3aa81"
      },
      "source": [
        "init_seeds(seed=1019)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7fa148d41250>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxVwRvRclImg",
        "outputId": "aaa8080c-abe4-4012-a805-e55aa77fe7df"
      },
      "source": [
        "df = pd.read_csv('MaritimeTrade_10-19_MLP.csv', low_memory=False)\n",
        "print('Number of rows and columns:', df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows and columns: (26088280, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U53zsz1q24mw",
        "outputId": "82b6b033-c9b2-40bb-f05e-166713d630fb"
      },
      "source": [
        "# Examine Variables for Missingness\n",
        "def missing_values_table(df):\n",
        "    mis_val = df.isnull().sum()\n",
        "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "    var_type = df.dtypes\n",
        "    mis_val_table = pd.concat([mis_val, mis_val_percent, var_type], axis=1)\n",
        "    mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns={0: 'Missing Values', 1: '% of Total Values', 2: 'Data Type'})\n",
        "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "    print('The selected dataframe has ' + str(df.shape[1]) + ' columns.\\n'\n",
        "          'There are ' + str(mis_val_table_ren_columns.shape[0]) +\n",
        "          ' columns that have missing values.')\n",
        "    return mis_val_table_ren_columns\n",
        "\n",
        "print('\\nInitial Missing Data Report') \n",
        "print(missing_values_table(df))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Missing Data Report\n",
            "The selected dataframe has 13 columns.\n",
            "There are 0 columns that have missing values.\n",
            "Empty DataFrame\n",
            "Columns: [Missing Values, % of Total Values, Data Type]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZXUjXcS201g",
        "outputId": "74d3e6e8-6174-46aa-a430-ab84f075478d"
      },
      "source": [
        "# Examine for other variables unable to impute probalistically\n",
        "def data_type_quality_table(df):\n",
        "        var_type = df.dtypes\n",
        "        unique_count = df.nunique()\n",
        "        val_table = pd.concat([var_type, unique_count], axis=1)\n",
        "        val_table_ren_columns = val_table.rename(\n",
        "        columns = {0 : 'Data Type', 1 : 'Number Unique'})\n",
        "        print ('The selected dataframe has ' + str(df.shape[1]) + ' columns.\\n')\n",
        "        return val_table_ren_columns\n",
        "\n",
        "print('\\nData Type & Uniqueness Report') \n",
        "print(data_type_quality_table(df))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Type & Uniqueness Report\n",
            "The selected dataframe has 13 columns.\n",
            "\n",
            "                       Data Type  Number Unique\n",
            "Container_LCL/FCL         object              2\n",
            "Metric_Tons              float64         151659\n",
            "Container_Type_Dry          bool              2\n",
            "TCVUSD                   float64        9784472\n",
            "Trade_Direction           object              2\n",
            "Year                       int64             10\n",
            "us_company_size           object              6\n",
            "foreign_company_size      object              6\n",
            "US_Port_Coastal_Region    object              6\n",
            "Foreign_Country_Region    object             11\n",
            "HS_Group_Name             object              6\n",
            "US_Unemployment_Rate     float64             53\n",
            "Average_Tariff           float64           1583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiw-wEGpsIqS"
      },
      "source": [
        "# Reformat for X,y\n",
        "df2 = df.drop(['Metric_Tons'], axis=1)\n",
        "df1 = df.loc[:, ['Metric_Tons']]\n",
        "df = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "del df1, df2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ov9MVadmmTC",
        "outputId": "1b6d8252-c857-43f4-a791-96519cc1b3b0"
      },
      "source": [
        "# X,y for encoding\n",
        "X = df.drop(['Metric_Tons'], axis=1)\n",
        "y = df.iloc[:,:1]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26088280, 12)\n",
            "(26088280, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78w8tQ59pkm"
      },
      "source": [
        "# Set up train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify= X.Year, random_state = 1019)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ45WstYmmVr"
      },
      "source": [
        "# Training set: Encode variables using ranking - ordinal               \n",
        "ce_ord = ce.OrdinalEncoder(cols = ['foreign_company_size', 'us_company_size'])\n",
        "X_train = ce_ord.fit_transform(X_train, y_train['Metric_Tons'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXaOKp2WAB7I"
      },
      "source": [
        "# Testing set: Encode variables using ranking - ordinal               \n",
        "ce_ord = ce.OrdinalEncoder(cols = ['foreign_company_size', 'us_company_size'])\n",
        "X_test = ce_ord.fit_transform(X_test, y_test['Metric_Tons'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "XdlkQSsEu36o",
        "outputId": "5c459386-0bc7-415c-9c9a-b1196346810b"
      },
      "source": [
        "# Train: Create dummy variables for categorical variables\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Container_Type_Dry</th>\n",
              "      <th>TCVUSD</th>\n",
              "      <th>Year</th>\n",
              "      <th>us_company_size</th>\n",
              "      <th>foreign_company_size</th>\n",
              "      <th>US_Unemployment_Rate</th>\n",
              "      <th>Average_Tariff</th>\n",
              "      <th>Container_LCL/FCL_LCL</th>\n",
              "      <th>Trade_Direction_Import</th>\n",
              "      <th>US_Port_Coastal_Region_Northeast</th>\n",
              "      <th>US_Port_Coastal_Region_Northwest</th>\n",
              "      <th>US_Port_Coastal_Region_Other</th>\n",
              "      <th>US_Port_Coastal_Region_Southeast</th>\n",
              "      <th>US_Port_Coastal_Region_Southwest</th>\n",
              "      <th>Foreign_Country_Region_European Union</th>\n",
              "      <th>Foreign_Country_Region_Middle East &amp; North Africa</th>\n",
              "      <th>Foreign_Country_Region_North America</th>\n",
              "      <th>Foreign_Country_Region_Oceania</th>\n",
              "      <th>Foreign_Country_Region_Other East Asia (not China)</th>\n",
              "      <th>Foreign_Country_Region_Other Europe (not European Union)</th>\n",
              "      <th>Foreign_Country_Region_South America</th>\n",
              "      <th>Foreign_Country_Region_South Asia</th>\n",
              "      <th>Foreign_Country_Region_Southeast Asia</th>\n",
              "      <th>Foreign_Country_Region_Sub Saharan Africa</th>\n",
              "      <th>HS_Group_Name_Edible with Processing</th>\n",
              "      <th>HS_Group_Name_Finished Goods</th>\n",
              "      <th>HS_Group_Name_Pharma</th>\n",
              "      <th>HS_Group_Name_Raw Input</th>\n",
              "      <th>HS_Group_Name_Vices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10469850</th>\n",
              "      <td>True</td>\n",
              "      <td>38532.89</td>\n",
              "      <td>2014</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.2</td>\n",
              "      <td>7.29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18182491</th>\n",
              "      <td>True</td>\n",
              "      <td>22153.32</td>\n",
              "      <td>2018</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20616234</th>\n",
              "      <td>True</td>\n",
              "      <td>44206.83</td>\n",
              "      <td>2019</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.6</td>\n",
              "      <td>17.81</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2749909</th>\n",
              "      <td>True</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8.3</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16605327</th>\n",
              "      <td>True</td>\n",
              "      <td>14485.40</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>24.40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Container_Type_Dry  ...  HS_Group_Name_Vices\n",
              "10469850                True  ...                    0\n",
              "18182491                True  ...                    0\n",
              "20616234                True  ...                    0\n",
              "2749909                 True  ...                    0\n",
              "16605327                True  ...                    0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYNLGVVwNZRP",
        "outputId": "4cf64b0c-10bb-45a1-9040-0d93b01c8101"
      },
      "source": [
        "print('Dimensions of X_train for input:', X_train.shape[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of X_train for input: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "E8a5Q-UkvcwG",
        "outputId": "005b9c52-877d-49b5-b7d8-e25a979e4dce"
      },
      "source": [
        "# Test: Create dummy variables for categorical variables\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "X_test.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Container_Type_Dry</th>\n",
              "      <th>TCVUSD</th>\n",
              "      <th>Year</th>\n",
              "      <th>us_company_size</th>\n",
              "      <th>foreign_company_size</th>\n",
              "      <th>US_Unemployment_Rate</th>\n",
              "      <th>Average_Tariff</th>\n",
              "      <th>Container_LCL/FCL_LCL</th>\n",
              "      <th>Trade_Direction_Import</th>\n",
              "      <th>US_Port_Coastal_Region_Northeast</th>\n",
              "      <th>US_Port_Coastal_Region_Northwest</th>\n",
              "      <th>US_Port_Coastal_Region_Other</th>\n",
              "      <th>US_Port_Coastal_Region_Southeast</th>\n",
              "      <th>US_Port_Coastal_Region_Southwest</th>\n",
              "      <th>Foreign_Country_Region_European Union</th>\n",
              "      <th>Foreign_Country_Region_Middle East &amp; North Africa</th>\n",
              "      <th>Foreign_Country_Region_North America</th>\n",
              "      <th>Foreign_Country_Region_Oceania</th>\n",
              "      <th>Foreign_Country_Region_Other East Asia (not China)</th>\n",
              "      <th>Foreign_Country_Region_Other Europe (not European Union)</th>\n",
              "      <th>Foreign_Country_Region_South America</th>\n",
              "      <th>Foreign_Country_Region_South Asia</th>\n",
              "      <th>Foreign_Country_Region_Southeast Asia</th>\n",
              "      <th>Foreign_Country_Region_Sub Saharan Africa</th>\n",
              "      <th>HS_Group_Name_Edible with Processing</th>\n",
              "      <th>HS_Group_Name_Finished Goods</th>\n",
              "      <th>HS_Group_Name_Pharma</th>\n",
              "      <th>HS_Group_Name_Raw Input</th>\n",
              "      <th>HS_Group_Name_Vices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21067397</th>\n",
              "      <td>False</td>\n",
              "      <td>22924.62</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>13.24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23343492</th>\n",
              "      <td>True</td>\n",
              "      <td>12584.06</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7.7</td>\n",
              "      <td>16.03</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3164049</th>\n",
              "      <td>True</td>\n",
              "      <td>9539.07</td>\n",
              "      <td>2014</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7.29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18037587</th>\n",
              "      <td>True</td>\n",
              "      <td>147823.99</td>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.44</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18234872</th>\n",
              "      <td>True</td>\n",
              "      <td>124340.94</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Container_Type_Dry  ...  HS_Group_Name_Vices\n",
              "21067397               False  ...                    0\n",
              "23343492                True  ...                    0\n",
              "3164049                 True  ...                    0\n",
              "18037587                True  ...                    0\n",
              "18234872                True  ...                    0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p9IhwKg7NjA"
      },
      "source": [
        "# MinMax Scaling\n",
        "mn = MinMaxScaler()\n",
        "X_train = pd.DataFrame(mn.fit_transform(X_train))\n",
        "X_test = pd.DataFrame(mn.fit_transform(X_test))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLoI31wGCg8w"
      },
      "source": [
        "log_folder = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#%load_ext tensorboard"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4msncLOCopP"
      },
      "source": [
        "# Set up callbacks\n",
        "filepath = 'MLP_weights_only_train1019_b64_HPO4.h5'\n",
        "\n",
        "checkpoint_dir = os.path.dirname(filepath)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_folder,\n",
        "                                                      histogram_freq=1)\n",
        "\n",
        "callbacks_list = [EarlyStopping(monitor='val_loss', patience = 5),\n",
        "                  ModelCheckpoint(filepath, monitor='mse', \n",
        "                                  save_best_only = True, mode='min'), \n",
        "                  tensorboard_callback]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqem_WQzrYau"
      },
      "source": [
        "# Define model for HPO\n",
        "def build_model(hp): \n",
        "  model = keras.Sequential()\n",
        "  for i in range(hp.Int(\"num_layers\", 7, 13)):\n",
        "        model.add(tf.keras.layers.Dense( units=hp.Int(\"layer_size\" + str(i), min_value=20, max_value=40, step=5),\n",
        "                activation=\"relu\", kernel_initializer='normal'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss=\"mae\", metrics=[\"mse\"], optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])))\n",
        "  return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWezzswVCwg5"
      },
      "source": [
        "# Define the search conditions \n",
        "tuner = BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=20,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"MLP_1019_HPO4\",\n",
        "    project_name=\"MLP_1019_HPO4\"\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8waScrkCwg7",
        "outputId": "1d5dd5d2-8d9b-4bc1-89bb-0d819cad75a9"
      },
      "source": [
        "# Print a summary of the search space\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 9\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 7, 'max_value': 13, 'step': 1, 'sampling': None}\n",
            "layer_size0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "layer_size1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "layer_size2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "layer_size3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "layer_size4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "layer_size5 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "layer_size6 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 40, 'step': 5, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5M_QTGNCwg8",
        "outputId": "a9f85015-658b-41b0-a55e-0f4e80b8ffb3"
      },
      "source": [
        "# Begin the search for the best hyperparameters \n",
        "tuner.search(X_train, y_train, epochs=1, validation_split=0.2, batch_size=64,\n",
        "             callbacks=callbacks_list)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 13m 16s]\n",
            "val_loss: 34.12989044189453\n",
            "\n",
            "Best val_loss So Far: 33.67256164550781\n",
            "Total elapsed time: 04h 25m 25s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM5I6bxVCwg8"
      },
      "source": [
        "# Retrieve the best model(s)\n",
        "models = tuner.get_best_models(num_models=2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qgiOcsqCwg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f496862a-b4ce-4f8b-fd95-c51da38e37fe"
      },
      "source": [
        "# Print a summary of the results from the trials\n",
        "tuner.results_summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in MLP_1019_HPO4/MLP_1019_HPO4\n",
            "Showing 10 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 35\n",
            "layer_size2: 30\n",
            "layer_size3: 30\n",
            "layer_size4: 30\n",
            "layer_size5: 30\n",
            "layer_size6: 25\n",
            "learning_rate: 0.001\n",
            "layer_size7: 35\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.67256164550781\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 40\n",
            "layer_size2: 20\n",
            "layer_size3: 40\n",
            "layer_size4: 30\n",
            "layer_size5: 40\n",
            "layer_size6: 25\n",
            "learning_rate: 0.01\n",
            "layer_size7: 40\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.73585891723633\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 40\n",
            "layer_size2: 40\n",
            "layer_size3: 35\n",
            "layer_size4: 30\n",
            "layer_size5: 25\n",
            "layer_size6: 30\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 40\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.85703659057617\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 25\n",
            "layer_size2: 40\n",
            "layer_size3: 40\n",
            "layer_size4: 25\n",
            "layer_size5: 20\n",
            "layer_size6: 35\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 25\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.865970611572266\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 20\n",
            "layer_size2: 40\n",
            "layer_size3: 40\n",
            "layer_size4: 20\n",
            "layer_size5: 20\n",
            "layer_size6: 20\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 35\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 40\n",
            "layer_size11: 20\n",
            "layer_size12: 20\n",
            "Score: 33.876068115234375\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 20\n",
            "layer_size2: 35\n",
            "layer_size3: 25\n",
            "layer_size4: 35\n",
            "layer_size5: 20\n",
            "layer_size6: 20\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 40\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.88157272338867\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 30\n",
            "layer_size2: 25\n",
            "layer_size3: 25\n",
            "layer_size4: 35\n",
            "layer_size5: 20\n",
            "layer_size6: 30\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 25\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.909236907958984\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 25\n",
            "layer_size2: 25\n",
            "layer_size3: 35\n",
            "layer_size4: 20\n",
            "layer_size5: 40\n",
            "layer_size6: 20\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 35\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.91884994506836\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 11\n",
            "layer_size0: 40\n",
            "layer_size1: 35\n",
            "layer_size2: 25\n",
            "layer_size3: 40\n",
            "layer_size4: 40\n",
            "layer_size5: 35\n",
            "layer_size6: 20\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 40\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.93350601196289\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "layer_size0: 40\n",
            "layer_size1: 25\n",
            "layer_size2: 30\n",
            "layer_size3: 20\n",
            "layer_size4: 35\n",
            "layer_size5: 35\n",
            "layer_size6: 40\n",
            "learning_rate: 0.0001\n",
            "layer_size7: 40\n",
            "layer_size8: 40\n",
            "layer_size9: 40\n",
            "layer_size10: 20\n",
            "layer_size11: 40\n",
            "layer_size12: 20\n",
            "Score: 33.940948486328125\n"
          ]
        }
      ]
    }
  ]
}